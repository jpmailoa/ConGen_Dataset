{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a922ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:14:48.707834Z",
     "iopub.status.busy": "2022-12-14T07:14:48.707508Z",
     "iopub.status.idle": "2022-12-14T07:14:50.337450Z",
     "shell.execute_reply": "2022-12-14T07:14:50.336811Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, argparse\n",
    "from build_nnfps import main as build_nnfps_main\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "import pickle, math\n",
    "from preprocessing import data_preparation, _char_set, get_property, canonocalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import SSVAE\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ece08b",
   "metadata": {},
   "source": [
    "# Molecule fingerprint regeneration for transfer learning, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbba225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:14:50.340760Z",
     "iopub.status.busy": "2022-12-14T07:14:50.340224Z",
     "iopub.status.idle": "2022-12-14T07:14:50.345382Z",
     "shell.execute_reply": "2022-12-14T07:14:50.344845Z"
    }
   },
   "outputs": [],
   "source": [
    "# training datafiles to use, pick the combination as you like\n",
    "csv_files = ['./data/paper_MP_IE_EA.csv',\n",
    "             './data/paper_MP_clean_canonize_cut.csv',\n",
    "             './data/paper_ZINC_310k.csv',\n",
    "             './data/paper_clean_viscosity.csv',\n",
    "             './data/paper_pubchem_fluorocarbon.csv'] \n",
    "# 'data/paper_clean_DC.csv' is skipped for now because it has many wrong & unphysical labels because of NLP\n",
    "\n",
    "out_pkl = 'data/smiles2nn.pkl'\n",
    "if os.path.isfile(out_pkl):\n",
    "    os.system('rm '+out_pkl)\n",
    "\n",
    "first = True\n",
    "for csv_file in csv_files:\n",
    "    args = argparse.Namespace()\n",
    "    args.csv_file = csv_file\n",
    "    if first:\n",
    "        args.input_vocab_file = ''\n",
    "        args.output_vocab_file = out_pkl\n",
    "        args.fp_check = False\n",
    "        # build_nnfps_main(args)\n",
    "        first = False\n",
    "    else:\n",
    "        args.input_vocab_file = out_pkl\n",
    "        args.output_vocab_file = out_pkl\n",
    "        args.fp_check = False\n",
    "        # build_nnfps_main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd70d4",
   "metadata": {},
   "source": [
    "# Prepare Combination of Dirty Data for Training SSVAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8435ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:14:50.347999Z",
     "iopub.status.busy": "2022-12-14T07:14:50.347522Z",
     "iopub.status.idle": "2022-12-14T07:20:25.157871Z",
     "shell.execute_reply": "2022-12-14T07:20:25.157245Z"
    }
   },
   "outputs": [],
   "source": [
    "# are we doing pre-training version? if yes, change pretrain to True\n",
    "pretrain = False\n",
    "pretrain_pkl = 'data/smiles2nn.pkl'\n",
    "\n",
    "# we will try train generative model with these training data files\n",
    "if 'csv_files' in locals():\n",
    "    data_uri = csv_files\n",
    "else:\n",
    "    data_uri = ['./data/paper_MP_IE_EA.csv',\n",
    "                './data/paper_MP_clean_canonize_cut.csv',\n",
    "                './data/paper_ZINC_310k.csv',\n",
    "                './data/paper_clean_viscosity.csv',\n",
    "                './data/paper_pubchem_fluorocarbon.csv'] \n",
    "\n",
    "# first check how many data points we have in the training data\n",
    "tmp_smiles = {}\n",
    "for csv_in in data_uri:\n",
    "    data = pds.read_csv( csv_in )\n",
    "    for i in range(len(data['SMILES'])):\n",
    "        tmp_smiles[ canonocalize(data['SMILES'][i]) ] = True\n",
    "\n",
    "# define training, validation, and test set division\n",
    "ntotal = len(tmp_smiles)\n",
    "ntrn = math.floor( 0.9 * ntotal )\n",
    "ntst = ntotal - ntrn\n",
    "frac_val = 0.05\n",
    "del data, tmp_smiles\n",
    "\n",
    "# data preparation\n",
    "if pretrain:\n",
    "    data, scaler_Y = data_preparation(data_uri, ntrn, ntst,\n",
    "                                      frac_val = frac_val,\n",
    "                                      pretrain_uri = pretrain_pkl)\n",
    "else:\n",
    "    data, scaler_Y = data_preparation(data_uri, ntrn, ntst,\n",
    "                                      frac_val = frac_val)\n",
    "\n",
    "# tag for dumping intermediate models\n",
    "dt = '221122121322'\n",
    "model_dir = 'models/'+dt\n",
    "tmp_model_tag = model_dir+'/'    \n",
    "scaler_Y_pkl = 'preprocessed_scaler_Y.pkl'\n",
    "scaler_Y = pickle.load(open(tmp_model_tag+scaler_Y_pkl,'rb'))\n",
    "\n",
    "print('::: Data preparation completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e79e0c",
   "metadata": {},
   "source": [
    "# Load Previously Trained Model, if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04251d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:20:25.160796Z",
     "iopub.status.busy": "2022-12-14T07:20:25.160276Z",
     "iopub.status.idle": "2022-12-14T07:20:29.348179Z",
     "shell.execute_reply": "2022-12-14T07:20:29.347599Z"
    }
   },
   "outputs": [],
   "source": [
    "# pre-defined parameters\n",
    "beta=10000.\n",
    "char_set = _char_set()\n",
    "dim_z = 100\n",
    "dim_h = 250\n",
    "n_hidden = 3\n",
    "batch_size = 100\n",
    "\n",
    "# tag for dumping intermediate models\n",
    "save_uri = tmp_model_tag+'model_final.pth.tar'\n",
    "\n",
    "# Instantiate the model\n",
    "model = SSVAE.TorchModel(sample_data = data, dim_z = dim_z, dim_h = dim_h,\n",
    "                         n_hidden = n_hidden, batch_size = batch_size, beta = float(beta), char_set = char_set,\n",
    "                         tmp_model_tag = tmp_model_tag)\n",
    "dev = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.initialize(torch.Tensor(data['trnY']), torch.Tensor(data['trnMask']), dev)\n",
    "model.load_state_dict( torch.load(save_uri)['state_dict'] )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821666a9",
   "metadata": {},
   "source": [
    "# Property Prediction Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c79c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:20:29.351111Z",
     "iopub.status.busy": "2022-12-14T07:20:29.350626Z",
     "iopub.status.idle": "2022-12-14T07:21:18.623182Z",
     "shell.execute_reply": "2022-12-14T07:21:18.622579Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_tstY_hat = model.predict_routine(sample_data = data).detach().cpu().numpy()\n",
    "tstY_hat = [scaler_Y[i].inverse_transform(scaled_tstY_hat[:,i:i+1]) for i in range(scaled_tstY_hat.shape[1])]\n",
    "tstY_hat = np.concatenate(tstY_hat, axis=1)\n",
    "\n",
    "dim_y = data['dim_y']\n",
    "tstY = data['tstY']\n",
    "tstMask = data['tstMask']\n",
    "Y_names = data['Y_names']\n",
    "for j in range(dim_y):\n",
    "    idx = np.where( tstMask[:,j] == 1 )[0]\n",
    "    print('Label Name:', Y_names[j])\n",
    "    print([j, mean_absolute_error(tstY[idx,j], tstY_hat[idx,j])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e309f8",
   "metadata": {},
   "source": [
    "# Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c031ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:21:18.626102Z",
     "iopub.status.busy": "2022-12-14T07:21:18.625571Z",
     "iopub.status.idle": "2022-12-14T07:21:59.799326Z",
     "shell.execute_reply": "2022-12-14T07:21:59.798726Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Unconditional')\n",
    "for t in range(10):\n",
    "    smi = model.sampling_unconditional()\n",
    "    print([t, smi, get_property(smi)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce543a",
   "metadata": {},
   "source": [
    "# Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45515b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T07:21:59.802439Z",
     "iopub.status.busy": "2022-12-14T07:21:59.801917Z",
     "iopub.status.idle": "2022-12-16T16:35:11.127486Z",
     "shell.execute_reply": "2022-12-16T16:35:11.126813Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_log(text):\n",
    "    out_file = 'gen_log.txt'\n",
    "    if os.path.isfile(out_file):\n",
    "        open(out_file,'a').write(text+'\\n')\n",
    "    else:\n",
    "        open(out_file,'w').write(text+'\\n')\n",
    "    return\n",
    "\n",
    "print('Conditional')\n",
    "# Determine the property values we want to use for conditional generation\n",
    "ynames = ['EA', 'IE', 'LogVis', 'MolWt', 'n_F', 'n_O']\n",
    "yids = [Y_names.index(yname) for yname in ynames]\n",
    "\n",
    "for i in range(50000):\n",
    "    i1 = random.sample([j*0.2 for j in range(11)], 1)[0]\n",
    "    i2 = random.sample([j*0.2 + 6.0 for j in range(11)], 1)[0]\n",
    "    i3 = random.sample([j*0.1 - 0.5 for j in range(11)], 1)[0]\n",
    "    i4 = random.sample([j*10 + 150 for j in range(21)], 1)[0]\n",
    "    i5 = random.sample([j*1.0 for j in range(4,10)], 1)[0]\n",
    "    i6 = random.sample([j*1.0 for j in range(1,4)], 1)[0]\n",
    "\n",
    "    ytargets = [i1,i2,i3,i4,i5,i6]\n",
    "    ymeans = np.array([scaler_Y[yid].mean_[0] for yid in yids])\n",
    "    ystds = np.array([np.sqrt(scaler_Y[yid].var_[0]) for yid in yids])\n",
    "    ytargets_transform = ( np.array(ytargets) - ymeans ) / ystds\n",
    "    \n",
    "    print(ynames, ':', ytargets)\n",
    "    smi = model.sampling_conditional(yids, ytargets_transform)\n",
    "    props = get_property(smi)\n",
    "    print([i, smi, props])\n",
    "    print_log(str([i, smi, props]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed4e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
